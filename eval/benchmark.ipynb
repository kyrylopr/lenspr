{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LensPR Benchmark: With vs Without\n",
    "\n",
    "Measures code reliability and context usage when using Claude with LensPR tools vs standard tools.\n",
    "\n",
    "## Metrics\n",
    "- **Input tokens** — context burned\n",
    "- **Output tokens** — generated\n",
    "- **Iterations** — conversation turns\n",
    "- **Tool calls** — which tools and how many\n",
    "- **Success** — task completed correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: /Users/kyryloprymak/code/lenspr\n",
      "LensPR initialized: True\n",
      "API key loaded: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "\n",
    "# Load API key from .env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import anthropic\n",
    "import lenspr\n",
    "\n",
    "# Initialize\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "RESULTS_DIR = Path('results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "client = anthropic.Anthropic()  # Uses ANTHROPIC_API_KEY from env\n",
    "ctx = lenspr.init(str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project: {PROJECT_ROOT}\")\n",
    "print(f\"LensPR initialized: {ctx is not None}\")\n",
    "print(f\"API key loaded: {'ANTHROPIC_API_KEY' in os.environ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BenchmarkResult:\n",
    "    \"\"\"Stores results from a single benchmark run.\"\"\"\n",
    "    task_id: str\n",
    "    mode: str  # 'with_lenspr' or 'without_lenspr'\n",
    "    \n",
    "    # Token metrics\n",
    "    total_input_tokens: int = 0\n",
    "    total_output_tokens: int = 0\n",
    "    \n",
    "    # Iteration metrics\n",
    "    iterations: int = 0\n",
    "    \n",
    "    # Tool usage\n",
    "    tool_calls: list = field(default_factory=list)\n",
    "    tool_call_count: int = 0\n",
    "    \n",
    "    # Success metrics\n",
    "    completed: bool = False\n",
    "    error: str | None = None\n",
    "    \n",
    "    # Timing\n",
    "    started_at: str = \"\"\n",
    "    finished_at: str = \"\"\n",
    "    duration_seconds: float = 0.0\n",
    "    \n",
    "    # Conversation log\n",
    "    messages: list = field(default_factory=list)\n",
    "    \n",
    "    def save(self, path: Path):\n",
    "        \"\"\"Save results to JSON.\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(asdict(self), f, indent=2, default=str)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path: Path) -> 'BenchmarkResult':\n",
    "        \"\"\"Load results from JSON.\"\"\"\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        return cls(**data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard tools: 6\n",
      "LensPR tools: 34 (28 lens_* + 6 standard)\n"
     ]
    }
   ],
   "source": [
    "# Standard tools (without LensPR)\n",
    "STANDARD_TOOLS = [\n",
    "    {\n",
    "        \"name\": \"read_file\",\n",
    "        \"description\": \"Read a file from the filesystem. Returns the file content.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"path\": {\"type\": \"string\", \"description\": \"Path to the file to read\"}\n",
    "            },\n",
    "            \"required\": [\"path\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"write_file\",\n",
    "        \"description\": \"Write content to a file. Creates or overwrites the file.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"path\": {\"type\": \"string\", \"description\": \"Path to the file\"},\n",
    "                \"content\": {\"type\": \"string\", \"description\": \"Content to write\"}\n",
    "            },\n",
    "            \"required\": [\"path\", \"content\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"search_files\",\n",
    "        \"description\": \"Search for a pattern in files using grep. Returns matching lines with file paths.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"pattern\": {\"type\": \"string\", \"description\": \"Pattern to search for\"},\n",
    "                \"path\": {\"type\": \"string\", \"description\": \"Directory to search in\", \"default\": \".\"}\n",
    "            },\n",
    "            \"required\": [\"pattern\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"list_files\",\n",
    "        \"description\": \"List files in a directory.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"path\": {\"type\": \"string\", \"description\": \"Directory path\", \"default\": \".\"}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"run_tests\",\n",
    "        \"description\": \"Run pytest on the project. Returns test output.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"path\": {\"type\": \"string\", \"description\": \"Test path\", \"default\": \"tests/\"}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"task_complete\",\n",
    "        \"description\": \"Call this when the task is complete. Provide a summary of what was done.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"summary\": {\"type\": \"string\", \"description\": \"Summary of completed work\"}\n",
    "            },\n",
    "            \"required\": [\"summary\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# LensPR tools (from lenspr package)\n",
    "LENSPR_TOOLS = lenspr.get_claude_tools() + STANDARD_TOOLS\n",
    "\n",
    "print(f\"Standard tools: {len(STANDARD_TOOLS)}\")\n",
    "print(f\"LensPR tools: {len(LENSPR_TOOLS)} ({len(LENSPR_TOOLS) - len(STANDARD_TOOLS)} lens_* + {len(STANDARD_TOOLS)} standard)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenspr/__init__.py\n",
      "lenspr/claude_tools.py\n",
      "lenspr/cli.py\n",
      "lenspr/context.py\n",
      "lenspr/database.py\n",
      "lenspr/graph.py\n",
      "lenspr/mcp_server.py\n",
      "lenspr/models.py\n",
      "lenspr/parsers/__init__.py\n",
      "lenspr/parsers/base.py\n",
      "lenspr/parsers/python_parser.py\n",
      "lenspr/patcher.py\n",
      "lenspr/plugins/__init__.py\n",
      "lenspr/tools/__init__.py\n",
      "lenspr/tools/analysis.py\n",
      "lenspr/tools/annotation.py\n",
      "lenspr/tools/explain.py\n",
      "lenspr/tools/git.py\n",
      "lenspr/tools/helpers.py\n",
      "lenspr/tools/modification.py\n",
      "lenspr/tools/navigation.py\n",
      "lenspr/tools/schemas.py\n",
      "l\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def handle_standard_tool(name: str, inputs: dict) -> str:\n",
    "    \"\"\"Handle standard tool calls.\"\"\"\n",
    "    try:\n",
    "        if name == \"read_file\":\n",
    "            path = PROJECT_ROOT / inputs[\"path\"]\n",
    "            if not path.exists():\n",
    "                return f\"Error: File not found: {inputs['path']}\"\n",
    "            return path.read_text()\n",
    "        \n",
    "        elif name == \"write_file\":\n",
    "            path = PROJECT_ROOT / inputs[\"path\"]\n",
    "            path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            path.write_text(inputs[\"content\"])\n",
    "            return f\"Successfully wrote {len(inputs['content'])} characters to {inputs['path']}\"\n",
    "        \n",
    "        elif name == \"search_files\":\n",
    "            search_path = PROJECT_ROOT / inputs.get(\"path\", \".\")\n",
    "            result = subprocess.run(\n",
    "                [\"grep\", \"-rn\", inputs[\"pattern\"], str(search_path)],\n",
    "                capture_output=True, text=True, timeout=30\n",
    "            )\n",
    "            output = result.stdout or \"No matches found\"\n",
    "            # Limit output size\n",
    "            if len(output) > 10000:\n",
    "                output = output[:10000] + f\"\\n... (truncated, {len(output)} total chars)\"\n",
    "            return output\n",
    "        \n",
    "        elif name == \"list_files\":\n",
    "            path = PROJECT_ROOT / inputs.get(\"path\", \".\")\n",
    "            if not path.exists():\n",
    "                return f\"Error: Directory not found: {inputs.get('path', '.')}\"\n",
    "            files = []\n",
    "            for p in sorted(path.rglob(\"*.py\"))[:100]:  # Limit to 100 files\n",
    "                rel = p.relative_to(PROJECT_ROOT)\n",
    "                files.append(str(rel))\n",
    "            return \"\\n\".join(files) if files else \"No Python files found\"\n",
    "        \n",
    "        elif name == \"run_tests\":\n",
    "            test_path = inputs.get(\"path\", \"tests/\")\n",
    "            result = subprocess.run(\n",
    "                [\"python\", \"-m\", \"pytest\", test_path, \"-v\", \"--tb=short\"],\n",
    "                capture_output=True, text=True, timeout=120, cwd=str(PROJECT_ROOT)\n",
    "            )\n",
    "            output = result.stdout + result.stderr\n",
    "            if len(output) > 15000:\n",
    "                output = output[:15000] + \"\\n... (truncated)\"\n",
    "            return output\n",
    "        \n",
    "        elif name == \"task_complete\":\n",
    "            return f\"TASK_COMPLETE: {inputs.get('summary', 'No summary')}\"\n",
    "        \n",
    "        else:\n",
    "            return f\"Unknown tool: {name}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error executing {name}: {str(e)}\"\n",
    "\n",
    "\n",
    "def handle_tool_call(name: str, inputs: dict) -> str:\n",
    "    \"\"\"Route tool call to appropriate handler.\"\"\"\n",
    "    if name.startswith(\"lens_\"):\n",
    "        result = lenspr.handle_tool(name, inputs)\n",
    "        return json.dumps(result, indent=2, default=str)\n",
    "    else:\n",
    "        return handle_standard_tool(name, inputs)\n",
    "\n",
    "# Test\n",
    "print(handle_standard_tool(\"list_files\", {\"path\": \"lenspr\"})[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agentic Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(\n",
    "    task: str,\n",
    "    tools: list,\n",
    "    system_prompt: str,\n",
    "    max_iterations: int = 20,\n",
    "    model: str = \"claude-sonnet-4-20250514\"\n",
    ") -> BenchmarkResult:\n",
    "    \"\"\"\n",
    "    Run Claude agent until task_complete is called or max_iterations reached.\n",
    "    \n",
    "    Returns BenchmarkResult with all metrics.\n",
    "    \"\"\"\n",
    "    result = BenchmarkResult(\n",
    "        task_id=\"\",\n",
    "        mode=\"with_lenspr\" if any(t[\"name\"].startswith(\"lens_\") for t in tools) else \"without_lenspr\",\n",
    "        started_at=datetime.now().isoformat()\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": task}]\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        result.iterations += 1\n",
    "        print(f\"\\n--- Iteration {result.iterations} ---\")\n",
    "        \n",
    "        # Call Claude\n",
    "        response = client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=4096,\n",
    "            system=system_prompt,\n",
    "            tools=tools,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        # Track tokens\n",
    "        result.total_input_tokens += response.usage.input_tokens\n",
    "        result.total_output_tokens += response.usage.output_tokens\n",
    "        \n",
    "        print(f\"Tokens: +{response.usage.input_tokens} in, +{response.usage.output_tokens} out\")\n",
    "        \n",
    "        # Process response\n",
    "        assistant_content = response.content\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_content})\n",
    "        \n",
    "        # Check for text output\n",
    "        for block in assistant_content:\n",
    "            if hasattr(block, 'text'):\n",
    "                print(f\"Claude: {block.text[:200]}...\" if len(block.text) > 200 else f\"Claude: {block.text}\")\n",
    "        \n",
    "        # Handle tool use\n",
    "        if response.stop_reason == \"tool_use\":\n",
    "            tool_results = []\n",
    "            \n",
    "            for block in assistant_content:\n",
    "                if block.type == \"tool_use\":\n",
    "                    tool_name = block.name\n",
    "                    tool_input = block.input\n",
    "                    \n",
    "                    result.tool_calls.append({\"name\": tool_name, \"input\": tool_input})\n",
    "                    result.tool_call_count += 1\n",
    "                    \n",
    "                    print(f\"Tool: {tool_name}({json.dumps(tool_input)[:100]}...)\")\n",
    "                    \n",
    "                    # Check for task completion\n",
    "                    if tool_name == \"task_complete\":\n",
    "                        result.completed = True\n",
    "                        result.finished_at = datetime.now().isoformat()\n",
    "                        result.messages = [{\"role\": m[\"role\"], \"content\": str(m[\"content\"])[:500]} for m in messages]\n",
    "                        print(f\"\\n✅ Task completed: {tool_input.get('summary', '')}\")\n",
    "                        return result\n",
    "                    \n",
    "                    # Execute tool\n",
    "                    tool_result = handle_tool_call(tool_name, tool_input)\n",
    "                    tool_results.append({\n",
    "                        \"type\": \"tool_result\",\n",
    "                        \"tool_use_id\": block.id,\n",
    "                        \"content\": tool_result[:5000]  # Limit result size\n",
    "                    })\n",
    "            \n",
    "            messages.append({\"role\": \"user\", \"content\": tool_results})\n",
    "        \n",
    "        elif response.stop_reason == \"end_turn\":\n",
    "            # Claude finished without tool call - might need prompting\n",
    "            print(\"Claude stopped without completing. Prompting to continue...\")\n",
    "            messages.append({\"role\": \"user\", \"content\": \"Please continue with the task. Use the task_complete tool when done.\"})\n",
    "    \n",
    "    # Max iterations reached\n",
    "    result.error = f\"Max iterations ({max_iterations}) reached\"\n",
    "    result.finished_at = datetime.now().isoformat()\n",
    "    result.messages = [{\"role\": m[\"role\"], \"content\": str(m[\"content\"])[:500]} for m in messages]\n",
    "    print(f\"\\n❌ Max iterations reached\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompts defined\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT_WITHOUT_LENSPR = \"\"\"\n",
    "You are a code assistant working on a Python project.\n",
    "\n",
    "Available tools:\n",
    "- read_file: Read file contents\n",
    "- write_file: Write to files\n",
    "- search_files: Search with grep\n",
    "- list_files: List Python files\n",
    "- run_tests: Run pytest\n",
    "- task_complete: Call when done\n",
    "\n",
    "Project root: lenspr/ (a Python code analysis library)\n",
    "\n",
    "Rules:\n",
    "1. Complete the task fully\n",
    "2. Update ALL affected files\n",
    "3. Run tests to verify\n",
    "4. Call task_complete when done\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_WITH_LENSPR = \"\"\"\n",
    "You are a code assistant working on a Python project with LensPR code graph tools.\n",
    "\n",
    "IMPORTANT: Use LensPR tools for Python code:\n",
    "- lens_context: Get function + callers + callees + tests (use this first!)\n",
    "- lens_check_impact: ALWAYS check before modifying code\n",
    "- lens_find_usages: Find all references to a function\n",
    "- lens_validate_change: Validate code before applying\n",
    "- lens_update_node: Update a function's code\n",
    "- lens_search: Search by name\n",
    "- lens_grep: Search in code with graph context\n",
    "\n",
    "Standard tools (for non-Python or when needed):\n",
    "- read_file, write_file, search_files, list_files, run_tests\n",
    "- task_complete: Call when done\n",
    "\n",
    "Project root: lenspr/ (a Python code analysis library)\n",
    "\n",
    "Rules:\n",
    "1. Use lens_check_impact BEFORE any code changes\n",
    "2. Use lens_context to understand functions\n",
    "3. Complete the task fully\n",
    "4. Run tests to verify\n",
    "5. Call task_complete when done\n",
    "\"\"\"\n",
    "\n",
    "print(\"System prompts defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 3 evaluation tasks\n",
      "  - task1_understand: Understand a function\n",
      "  - task2_find_usages: Find all usages\n",
      "  - task3_safe_change: Safe code change\n"
     ]
    }
   ],
   "source": [
    "TASKS = {\n",
    "    \"task1_understand\": {\n",
    "        \"name\": \"Understand a function\",\n",
    "        \"prompt\": \"\"\"\n",
    "Analyze the function `check_impact` in lenspr/graph.py.\n",
    "\n",
    "Tell me:\n",
    "1. What does it do?\n",
    "2. What functions call it?\n",
    "3. What functions does it call?\n",
    "4. What tests cover it?\n",
    "\n",
    "Call task_complete with your analysis.\n",
    "\"\"\",\n",
    "        \"expected\": [\"get_impact_zone\", \"callers\", \"callees\", \"tests\"]\n",
    "    },\n",
    "    \n",
    "    \"task2_find_usages\": {\n",
    "        \"name\": \"Find all usages\",\n",
    "        \"prompt\": \"\"\"\n",
    "Find ALL places where the function `get_node` from lenspr/database.py is used.\n",
    "\n",
    "List:\n",
    "1. All files that import it\n",
    "2. All functions that call it\n",
    "3. All tests that use it\n",
    "\n",
    "Call task_complete with the complete list.\n",
    "\"\"\",\n",
    "        \"expected\": [\"callers\", \"importers\"]\n",
    "    },\n",
    "    \n",
    "    \"task3_safe_change\": {\n",
    "        \"name\": \"Safe code change\",\n",
    "        \"prompt\": \"\"\"\n",
    "I want to add a new parameter `include_external: bool = False` to the function \n",
    "`get_connections` in lenspr/database.py.\n",
    "\n",
    "Before making ANY changes:\n",
    "1. Analyze what will be affected by this change\n",
    "2. List all callers that might need updates\n",
    "3. Tell me the severity/risk of this change\n",
    "\n",
    "DO NOT actually make the change - just analyze the impact.\n",
    "Call task_complete with your analysis.\n",
    "\"\"\",\n",
    "        \"expected\": [\"impact\", \"severity\", \"callers\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(TASKS)} evaluation tasks\")\n",
    "for task_id, task in TASKS.items():\n",
    "    print(f\"  - {task_id}: {task['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(task_id: str, with_lenspr: bool) -> BenchmarkResult:\n",
    "    \"\"\"Run a single benchmark task.\"\"\"\n",
    "    task = TASKS[task_id]\n",
    "    mode = \"with_lenspr\" if with_lenspr else \"without_lenspr\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running: {task['name']} ({mode})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    tools = LENSPR_TOOLS if with_lenspr else STANDARD_TOOLS\n",
    "    system = SYSTEM_PROMPT_WITH_LENSPR if with_lenspr else SYSTEM_PROMPT_WITHOUT_LENSPR\n",
    "    \n",
    "    result = run_agent(\n",
    "        task=task[\"prompt\"],\n",
    "        tools=tools,\n",
    "        system_prompt=system,\n",
    "        max_iterations=15\n",
    "    )\n",
    "    \n",
    "    result.task_id = task_id\n",
    "    result.mode = mode\n",
    "    \n",
    "    # Save result\n",
    "    result_path = RESULTS_DIR / f\"{task_id}_{mode}.json\"\n",
    "    result.save(result_path)\n",
    "    print(f\"\\nSaved: {result_path}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understand a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: Understand a function (without_lenspr)\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Tokens: +956 in, +96 out\n",
      "Claude: I'll analyze the `check_impact` function in lenspr/graph.py for you. Let me start by examining the function and then trace its usage and dependencies.\n",
      "Tool: read_file({\"path\": \"lenspr/graph.py\"}...)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Tokens: +2538 in, +97 out\n",
      "Claude: The file seems to be cut off. Let me search for the `check_impact` function specifically:\n",
      "Tool: search_files({\"pattern\": \"def check_impact\", \"path\": \"lenspr\"}...)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Tokens: +2694 in, +92 out\n",
      "Claude: The `check_impact` function is actually in `lenspr/__init__.py`, not in `graph.py`. Let me examine it there:\n",
      "Tool: read_file({\"path\": \"lenspr/__init__.py\"}...)\n",
      "\n",
      "--- Iteration 4 ---\n",
      "Tokens: +4309 in, +76 out\n",
      "Claude: The file is cut off again. Let me search for the specific function and its surrounding context:\n",
      "Tool: search_files({\"pattern\": \"def check_impact\"}...)\n",
      "\n",
      "--- Iteration 5 ---\n",
      "Tokens: +4469 in, +60 out\n",
      "Tool: search_files({\"pattern\": \"check_impact\\\" -A 15\"}...)\n",
      "\n",
      "--- Iteration 6 ---\n",
      "Tokens: +4544 in, +73 out\n",
      "Claude: Let me try a different approach to see the function:\n",
      "Tool: search_files({\"pattern\": \"check_impact.*:\\\" -A 20\"}...)\n",
      "\n",
      "--- Iteration 7 ---\n",
      "Tokens: +4632 in, +74 out\n",
      "Claude: Let me read around line 202 in the __init__.py file:\n",
      "Tool: search_files({\"pattern\": \"Get impact zone\"}...)\n",
      "\n",
      "--- Iteration 8 ---\n",
      "Tokens: +4719 in, +103 out\n",
      "Claude: Let me try to see the end of the __init__.py file:\n",
      "Tool: search_files({\"pattern\": \"def.*:\\\" -B 2 -A 10\", \"path\": \"lenspr/__init__.py\"}...)\n",
      "\n",
      "--- Iteration 9 ---\n",
      "Tokens: +4837 in, +65 out\n",
      "Claude: Let me try a simpler grep search:\n",
      "Tool: search_files({\"pattern\": \"check_impact\"}...)\n",
      "\n",
      "--- Iteration 10 ---\n",
      "Tokens: +6739 in, +69 out\n",
      "Claude: Let me check the claude_tools to see the tool implementation:\n",
      "Tool: list_files({\"path\": \"lenspr\"}...)\n",
      "\n",
      "--- Iteration 11 ---\n",
      "Tokens: +7048 in, +61 out\n",
      "Tool: read_file({\"path\": \"lenspr/claude_tools.py\"}...)\n",
      "\n",
      "--- Iteration 12 ---\n",
      "Tokens: +8063 in, +74 out\n",
      "Claude: Now let me check the actual implementation in the analysis module:\n",
      "Tool: read_file({\"path\": \"lenspr/tools/analysis.py\"}...)\n",
      "\n",
      "--- Iteration 13 ---\n",
      "Tokens: +9628 in, +71 out\n",
      "Claude: Let me continue reading the file to see what functions call it:\n",
      "Tool: search_files({\"pattern\": \"handle_check_impact\"}...)\n",
      "\n",
      "--- Iteration 14 ---\n",
      "Tokens: +11471 in, +78 out\n",
      "Claude: Let me check the tools/__init__.py file to understand the structure better:\n",
      "Tool: read_file({\"path\": \"lenspr/tools/__init__.py\"}...)\n",
      "\n",
      "--- Iteration 15 ---\n",
      "Tokens: +13153 in, +111 out\n",
      "Claude: Now let me check if there's a direct `check_impact` function in __init__.py:\n",
      "Tool: search_files({\"pattern\": \"\\\"check_impact\\\" -B 5 -A 10\", \"path\": \"lenspr/__init__.py\"}...)\n",
      "\n",
      "❌ Max iterations reached\n",
      "\n",
      "Saved: results/task1_understand_without_lenspr.json\n"
     ]
    }
   ],
   "source": [
    "# Run WITHOUT LensPR\n",
    "result_without = run_benchmark(\"task1_understand\", with_lenspr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: Understand a function (with_lenspr)\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Tokens: +4432 in, +183 out\n",
      "Claude: I'll analyze the `check_impact` function for you. Let me start by getting comprehensive context about this function.\n",
      "Tool: lens_context({\"node_id\": \"lenspr.graph.check_impact\", \"depth\": 2, \"include_callers\": true, \"include_callees\": tru...)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Tokens: +4699 in, +89 out\n",
      "Claude: Let me search for the function first to find its exact node ID:\n",
      "Tool: lens_search({\"query\": \"check_impact\", \"search_in\": \"name\"}...)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Tokens: +5210 in, +107 out\n",
      "Claude: I see there are multiple functions related to `check_impact`. Let me look in the graph.py file specifically:\n",
      "Tool: lens_list_nodes({\"file_path\": \"lenspr/graph.py\", \"name\": \"check_impact\"}...)\n",
      "\n",
      "--- Iteration 4 ---\n",
      "Tokens: +5387 in, +77 out\n",
      "Claude: Let me check what functions are in the graph.py file:\n",
      "Tool: lens_list_nodes({\"file_path\": \"lenspr/graph.py\"}...)\n",
      "\n",
      "--- Iteration 5 ---\n",
      "Tokens: +6473 in, +220 out\n",
      "Claude: I don't see a `check_impact` function in `lenspr/graph.py`. It seems there might be confusion about the location. Let me check the main `check_impact` function that's in the `__init__.py` file, which ...\n",
      "Tool: lens_context({\"node_id\": \"lenspr.check_impact\", \"depth\": 2, \"include_callers\": true, \"include_callees\": true, \"in...)\n",
      "\n",
      "--- Iteration 6 ---\n",
      "Tokens: +8202 in, +102 out\n",
      "Claude: Let me also check if there are any usage patterns by searching for references to this function:\n",
      "Tool: lens_find_usages({\"node_id\": \"lenspr.check_impact\", \"include_tests\": true}...)\n",
      "\n",
      "--- Iteration 7 ---\n",
      "Tokens: +8469 in, +163 out\n",
      "Claude: Let me also check the MCP server function that wraps this:\n",
      "Tool: lens_context({\"node_id\": \"lenspr.mcp_server.run_server.lens_check_impact\", \"depth\": 1, \"include_callers\": true, \"...)\n",
      "\n",
      "--- Iteration 8 ---\n",
      "Tokens: +10236 in, +162 out\n",
      "Claude: Now let me check the test coverage by looking at the handle_check_impact function:\n",
      "Tool: lens_context({\"node_id\": \"lenspr.tools.analysis.handle_check_impact\", \"depth\": 1, \"include_callers\": true, \"inclu...)\n",
      "\n",
      "--- Iteration 9 ---\n",
      "Tokens: +12042 in, +88 out\n",
      "Claude: Let me also check for tests:\n",
      "Tool: lens_search({\"query\": \"test_handle_tool_check_impact\", \"search_in\": \"name\"}...)\n",
      "\n",
      "--- Iteration 10 ---\n",
      "Tokens: +12307 in, +83 out\n",
      "Tool: lens_get_node({\"node_id\": \"tests.test_mcp_server.TestMCPToolWrappers.test_handle_tool_check_impact\"}...)\n",
      "\n",
      "--- Iteration 11 ---\n",
      "Tokens: +12714 in, +86 out\n",
      "Claude: Let me also check for additional test coverage:\n",
      "Tool: lens_grep({\"pattern\": \"check_impact\", \"file_glob\": \"tests/*.py\"}...)\n",
      "\n",
      "--- Iteration 12 ---\n",
      "Tokens: +13145 in, +108 out\n",
      "Claude: Now let me also examine the core `get_impact_zone` function that's being called:\n",
      "Tool: lens_find_usages({\"node_id\": \"lenspr.graph.get_impact_zone\", \"include_tests\": true}...)\n",
      "\n",
      "--- Iteration 13 ---\n",
      "Tokens: +14333 in, +731 out\n",
      "Tool: task_complete({\"summary\": \"## Analysis of `check_impact` Function\\n\\n**Note:** There is no `check_impact` function...)\n",
      "\n",
      "✅ Task completed: ## Analysis of `check_impact` Function\n",
      "\n",
      "**Note:** There is no `check_impact` function in `lenspr/graph.py`. The `check_impact` function is located in `lenspr/__init__.py`. Here's the complete analysis:\n",
      "\n",
      "### 1. What does it do?\n",
      "\n",
      "The `check_impact` function analyzes the potential impact of changing a specific node in the codebase. It:\n",
      "\n",
      "- Takes a `node_id` (string) and optional `depth` parameter (default 2)\n",
      "- Gets the current LensPR context and graph\n",
      "- Calls `get_impact_zone` from `lenspr.graph` module to perform the actual impact analysis\n",
      "- Returns a dictionary with information about affected nodes\n",
      "\n",
      "The core logic is in `get_impact_zone` which:\n",
      "- Finds all nodes that could be affected by changing the given node\n",
      "- Traverses incoming edges (who depends on this node) up to the specified depth\n",
      "- Returns direct callers, indirect callers, inheritors, total affected count, and untracked warnings\n",
      "- Distinguishes between regular calls and inheritance relationships\n",
      "\n",
      "### 2. What functions call it?\n",
      "\n",
      "**Direct callers:** None found in the current codebase - no functions directly call `lenspr.check_impact`\n",
      "\n",
      "**Indirect usage:** The function is accessed through:\n",
      "- **MCP Server wrapper**: `lens_check_impact` in `lenspr/mcp_server.py` - provides the MCP tool interface\n",
      "- **Tool handler**: `handle_check_impact` in `lenspr/tools/analysis.py` - adds severity analysis and warnings\n",
      "\n",
      "### 3. What functions does it call?\n",
      "\n",
      "The `check_impact` function calls:\n",
      "1. **`_require_ctx()`** - Validates that LensPR is initialized and returns the context\n",
      "2. **`get_impact_zone()`** from `lenspr.graph` - Performs the actual impact analysis\n",
      "3. Indirectly raises **`NotInitializedError`** if context is not available\n",
      "\n",
      "### 4. What tests cover it?\n",
      "\n",
      "**Limited test coverage:**\n",
      "- **`test_handle_tool_check_impact`** in `tests/test_mcp_server.py` - Tests the MCP tool wrapper only\n",
      "- **No direct tests** for the `check_impact` function itself\n",
      "- **Comprehensive tests** for the underlying `get_impact_zone` function in `tests/test_graph.py`:\n",
      "  - `test_direct_callers`\n",
      "  - `test_indirect_callers` \n",
      "  - `test_nonexistent_node`\n",
      "  - `test_leaf_node`\n",
      "\n",
      "**⚠️ Testing Gap:** The `check_impact` function lacks direct unit tests, though its core functionality is well-tested through `get_impact_zone` tests.\n",
      "\n",
      "### Usage Context\n",
      "\n",
      "This function is primarily accessed through the MCP server interface and tool dispatch system, making it a key component for impact analysis in the LensPR code analysis workflow.\n",
      "\n",
      "Saved: results/task1_understand_with_lenspr.json\n"
     ]
    }
   ],
   "source": [
    "# Run WITH LensPR\n",
    "result_with = run_benchmark(\"task1_understand\", with_lenspr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Find All Usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: Find all usages (without_lenspr)\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Tokens: +951 in, +99 out\n",
      "Claude: I'll help you find all places where the `get_node` function from `lenspr/database.py` is used. Let me start by exploring the project structure and then systematically search for all usages.\n",
      "Tool: list_files({\"path\": \".\"}...)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Tokens: +3104 in, +66 out\n",
      "Claude: Let me focus on the lenspr directory:\n",
      "Tool: list_files({\"path\": \"lenspr\"}...)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Tokens: +3410 in, +79 out\n",
      "Claude: Now let me check the database.py file to see the `get_node` function:\n",
      "Tool: read_file({\"path\": \"lenspr/database.py\"}...)\n",
      "\n",
      "--- Iteration 4 ---\n",
      "Tokens: +4907 in, +96 out\n",
      "Claude: Let me continue reading the database.py file to see the complete `get_node` function:\n",
      "Tool: search_files({\"pattern\": \"def get_node\", \"path\": \"lenspr\"}...)\n",
      "\n",
      "--- Iteration 5 ---\n",
      "Tokens: +5136 in, +75 out\n",
      "Claude: Now let me read the specific get_node function from database.py:\n",
      "Tool: read_file({\"path\": \"lenspr/database.py\"}...)\n",
      "\n",
      "--- Iteration 6 ---\n",
      "Tokens: +6629 in, +94 out\n",
      "Claude: Let me search more specifically around line 181 to find the get_node function:\n",
      "Tool: search_files({\"pattern\": \"get_node.*:\", \"path\": \"lenspr\"}...)\n",
      "\n",
      "--- Iteration 7 ---\n",
      "Tokens: +7189 in, +102 out\n",
      "Claude: Let me get the specific section of database.py around line 181:\n",
      "Tool: search_files({\"pattern\": \"-A 20 \\\"def get_node\\\"\", \"path\": \"lenspr/database.py\"}...)\n",
      "\n",
      "--- Iteration 8 ---\n",
      "Tokens: +7306 in, +103 out\n",
      "Claude: Let me use a different approach to see the specific lines around the get_node function:\n",
      "Tool: search_files({\"pattern\": \"def get_node.*Node.*None\\\"\", \"path\": \"lenspr/database.py\"}...)\n",
      "\n",
      "--- Iteration 9 ---\n",
      "Tokens: +7424 in, +95 out\n",
      "Claude: Let me read just the lines that contain get_node in database.py:\n",
      "Tool: search_files({\"pattern\": \"get_node\", \"path\": \"lenspr/database.py\"}...)\n",
      "\n",
      "--- Iteration 10 ---\n",
      "Tokens: +7611 in, +97 out\n",
      "Claude: Let me use a different approach to get the full content of database.py and find the function:\n",
      "Tool: search_files({\"pattern\": \".\\\"\", \"path\": \"lenspr/database.py\"}...)\n",
      "\n",
      "--- Iteration 11 ---\n",
      "Tokens: +9697 in, +79 out\n",
      "Claude: Now let me try to see the specific get_node function definition by reading a specific section:\n",
      "Tool: search_files({\"pattern\": \"from lenspr.database import\"}...)\n",
      "\n",
      "--- Iteration 12 ---\n",
      "Tokens: +10005 in, +77 out\n",
      "Claude: Great! Now let me search for all usages of `get_node` from the database module:\n",
      "Tool: search_files({\"pattern\": \"get_node\"}...)\n",
      "\n",
      "--- Iteration 13 ---\n",
      "Tokens: +11970 in, +73 out\n",
      "Claude: Now let me search more specifically for imports of the get_node function:\n",
      "Tool: search_files({\"pattern\": \"import.*get_node\"}...)\n",
      "\n",
      "--- Iteration 14 ---\n",
      "Tokens: +13735 in, +77 out\n",
      "Claude: Let me search for specific imports from lenspr.database:\n",
      "Tool: search_files({\"pattern\": \"from lenspr.database import.*get_node\"}...)\n",
      "\n",
      "--- Iteration 15 ---\n",
      "Tokens: +13930 in, +74 out\n",
      "Claude: Now let me look at the test file that imports get_node:\n",
      "Tool: read_file({\"path\": \"tests/test_database.py\"}...)\n",
      "\n",
      "❌ Max iterations reached\n",
      "\n",
      "Saved: results/task2_find_usages_without_lenspr.json\n"
     ]
    }
   ],
   "source": [
    "# Run WITHOUT LensPR\n",
    "result_without = run_benchmark(\"task2_find_usages\", with_lenspr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: Find all usages (with_lenspr)\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Tokens: +4427 in, +104 out\n",
      "Claude: I'll find all places where the `get_node` function from `lenspr/database.py` is used. Let me start by getting the context and then finding all usages.\n",
      "Tool: lens_context({\"node_id\": \"lenspr.database.get_node\"}...)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Tokens: +6257 in, +97 out\n",
      "Claude: Now let me find all usages of this function:\n",
      "Tool: lens_find_usages({\"node_id\": \"lenspr.database.get_node\", \"include_tests\": true}...)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Tokens: +8065 in, +105 out\n",
      "Claude: Let me also check for imports to get the complete picture:\n",
      "Tool: lens_grep({\"pattern\": \"from lenspr.database import.*get_node|import.*get_node.*from.*database\", \"max_results\":...)\n",
      "\n",
      "--- Iteration 4 ---\n",
      "Tokens: +8451 in, +88 out\n",
      "Claude: Now let me search more specifically for imports of get_node:\n",
      "Tool: lens_grep({\"pattern\": \"get_node\", \"max_results\": 100}...)\n",
      "\n",
      "--- Iteration 5 ---\n",
      "Tokens: +10353 in, +88 out\n",
      "Claude: Let me continue to get the rest of the results:\n",
      "Tool: lens_grep({\"pattern\": \"database.get_node\", \"max_results\": 100}...)\n",
      "\n",
      "--- Iteration 6 ---\n",
      "Tokens: +12179 in, +105 out\n",
      "Claude: Now let me check the test files specifically:\n",
      "Tool: lens_grep({\"pattern\": \"get_node\", \"file_glob\": \"tests/*.py\", \"max_results\": 50}...)\n",
      "\n",
      "--- Iteration 7 ---\n",
      "Tokens: +13942 in, +95 out\n",
      "Claude: Let me also check for any imports of the function in tool files:\n",
      "Tool: lens_grep({\"pattern\": \"from.*database.*import.*get_node\", \"max_results\": 50}...)\n",
      "\n",
      "--- Iteration 8 ---\n",
      "Tokens: +14306 in, +109 out\n",
      "Claude: Let me also check imports in the test files:\n",
      "Tool: lens_grep({\"pattern\": \"import.*get_node\\\"\", \"file_glob\": \"tests/*.py\", \"max_results\": 50}...)\n",
      "\n",
      "--- Iteration 9 ---\n",
      "Tokens: +14506 in, +93 out\n",
      "Claude: Let me check the database imports in various tool files:\n",
      "Tool: lens_grep({\"pattern\": \"from lenspr import database|import.*database\", \"max_results\": 50}...)\n",
      "\n",
      "--- Iteration 10 ---\n",
      "Tokens: +15878 in, +876 out\n",
      "Claude: Now I have all the information I need. Let me compile the complete list:\n",
      "Tool: task_complete({\"summary\": \"Found ALL places where `get_node` from `lenspr/database.py` is used:\\n\\n## 1. Files tha...)\n",
      "\n",
      "✅ Task completed: Found ALL places where `get_node` from `lenspr/database.py` is used:\n",
      "\n",
      "## 1. Files that import it:\n",
      "- `lenspr/__init__.py` - Direct import as `db_get_node`\n",
      "- `lenspr/tools/analysis.py` - Via `from lenspr import database`  \n",
      "- `lenspr/tools/annotation.py` - Via `from lenspr import database`\n",
      "- `lenspr/tools/explain.py` - Via `from lenspr import database`\n",
      "- `lenspr/tools/git.py` - Via `from lenspr import database`\n",
      "- `lenspr/tools/modification.py` - Via `from lenspr import database`\n",
      "- `lenspr/tools/navigation.py` - Via `from lenspr import database`\n",
      "- `tests/test_database.py` - Direct import\n",
      "- `tests/test_tool_operations.py` - Via `from lenspr import database`\n",
      "\n",
      "## 2. Functions that call it (27 total usages):\n",
      "**Core API:**\n",
      "- `lenspr.get_node` (lenspr/__init__.py)\n",
      "\n",
      "**Tools - Analysis:**\n",
      "- `lenspr.tools.analysis.handle_validate_change`\n",
      "- `lenspr.tools.analysis.handle_find_usages`\n",
      "\n",
      "**Tools - Annotation:**\n",
      "- `lenspr.tools.annotation.handle_annotate`\n",
      "- `lenspr.tools.annotation.handle_save_annotation`\n",
      "\n",
      "**Tools - Explain:**\n",
      "- `lenspr.tools.explain.handle_explain`\n",
      "- `lenspr.tools.explain._get_callers_context`\n",
      "- `lenspr.tools.explain._get_callees_context`\n",
      "\n",
      "**Tools - Git:**\n",
      "- `lenspr.tools.git.handle_blame`\n",
      "- `lenspr.tools.git.handle_node_history`\n",
      "\n",
      "**Tools - Modification:**\n",
      "- `lenspr.tools.modification.handle_update_node`\n",
      "- `lenspr.tools.modification.handle_add_node`\n",
      "- `lenspr.tools.modification.handle_delete_node`\n",
      "- `lenspr.tools.modification.handle_rename` (2 calls)\n",
      "- `lenspr.tools.modification.handle_batch`\n",
      "\n",
      "**Tools - Navigation:**\n",
      "- `lenspr.tools.navigation.handle_get_node`\n",
      "- `lenspr.tools.navigation.handle_context`\n",
      "\n",
      "## 3. Tests that use it:\n",
      "**Direct unit tests:**\n",
      "- `tests.test_database.TestGetNode.test_found`\n",
      "- `tests.test_database.TestGetNode.test_not_found`\n",
      "\n",
      "**Integration tests:**\n",
      "- `tests.test_database.TestUpdateAndDelete.test_update_source`\n",
      "- `tests.test_database.TestUpdateAndDelete.test_delete`\n",
      "- `tests.test_tool_operations.TestUpdateNode.test_update_reparses_graph`\n",
      "- `tests.test_tool_operations.TestUpdateNode.test_update_rejects_structure_change`\n",
      "- `tests.test_tool_operations.TestAddNode.test_add_reparses_graph`\n",
      "- `tests.test_tool_operations.TestDeleteNode.test_delete_removes_from_graph`\n",
      "\n",
      "**Total:** 9 files with imports, 17 unique functions calling it (27 total calls), 8 test methods using it directly.\n",
      "\n",
      "Saved: results/task2_find_usages_with_lenspr.json\n"
     ]
    }
   ],
   "source": [
    "# Run WITH LensPR\n",
    "result_with = run_benchmark(\"task2_find_usages\", with_lenspr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Safe Code Change Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: Safe code change (without_lenspr)\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Tokens: +990 in, +108 out\n",
      "Claude: I'll analyze the impact of adding the `include_external: bool = False` parameter to the `get_connections` function in `lenspr/database.py`. Let me start by examining the current codebase structure and...\n",
      "Tool: list_files({\"path\": \".\"}...)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Tokens: +3152 in, +74 out\n",
      "Claude: Let me look at the actual project structure by listing files in the lenspr directory:\n",
      "Tool: list_files({\"path\": \"lenspr\"}...)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Tokens: +3466 in, +82 out\n",
      "Claude: Now let me examine the current `get_connections` function in `lenspr/database.py`:\n",
      "Tool: read_file({\"path\": \"lenspr/database.py\"}...)\n",
      "\n",
      "--- Iteration 4 ---\n",
      "Tokens: +4966 in, +95 out\n",
      "Claude: Let me see the rest of the file and specifically find the `get_connections` function:\n",
      "Tool: search_files({\"pattern\": \"def get_connections\", \"path\": \"lenspr\"}...)\n",
      "\n",
      "--- Iteration 5 ---\n",
      "Tokens: +5122 in, +90 out\n",
      "Claude: The function is not in `database.py` but in `__init__.py`. Let me check the `__init__.py` file:\n",
      "Tool: read_file({\"path\": \"lenspr/__init__.py\"}...)\n",
      "\n",
      "--- Iteration 6 ---\n",
      "Tokens: +6735 in, +98 out\n",
      "Claude: Let me get the rest of the `get_connections` function:\n",
      "Tool: search_files({\"pattern\": \"get_connections\\\" -A 20\", \"path\": \"lenspr/__init__.py\"}...)\n",
      "\n",
      "--- Iteration 7 ---\n",
      "Tokens: +6848 in, +98 out\n",
      "Claude: Let me use a different approach to see the complete `get_connections` function:\n",
      "Tool: search_files({\"pattern\": \"def get_connections\\\" -A 15\", \"path\": \"lenspr\"}...)\n",
      "\n",
      "--- Iteration 8 ---\n",
      "Tokens: +6961 in, +87 out\n",
      "Claude: Let me see lines around the get_connections function definition:\n",
      "Tool: search_files({\"pattern\": \"get_connections\", \"path\": \"lenspr\"}...)\n",
      "\n",
      "--- Iteration 9 ---\n",
      "Tokens: +7930 in, +92 out\n",
      "Claude: Now let me read the complete `get_connections` function from `lenspr/__init__.py` by reading a larger portion around line 195:\n",
      "Tool: read_file({\"path\": \"lenspr/__init__.py\"}...)\n",
      "\n",
      "--- Iteration 10 ---\n",
      "Tokens: +9545 in, +108 out\n",
      "Claude: I need to see more of the file to get the complete function. Let me search for the function body:\n",
      "Tool: search_files({\"pattern\": \"def get_connections.*:\\\" -A 10\", \"path\": \"lenspr/__init__.py\"}...)\n",
      "\n",
      "--- Iteration 11 ---\n",
      "Tokens: +9668 in, +74 out\n",
      "Claude: Let me try a different approach and see the lines around 195:\n",
      "Tool: read_file({\"path\": \"lenspr/__init__.py\"}...)\n",
      "\n",
      "--- Iteration 12 ---\n",
      "Tokens: +11265 in, +111 out\n",
      "Claude: The file appears to be truncated. Let me see if there's a way to get the full file content. Let me try to look at specific lines:\n",
      "Tool: search_files({\"pattern\": \"\\\"both\\\")\", \"path\": \"lenspr/__init__.py\"}...)\n",
      "\n",
      "--- Iteration 13 ---\n",
      "Tokens: +11437 in, +87 out\n",
      "Claude: Let me check if the file has more content after this:\n",
      "Tool: search_files({\"pattern\": \"get_edges\", \"path\": \"lenspr\"}...)\n",
      "\n",
      "--- Iteration 14 ---\n",
      "Tokens: +11910 in, +110 out\n",
      "Claude: Perfect! Now I can see the complete function. Let me examine the `get_edges` function in the database module:\n",
      "Tool: search_files({\"pattern\": \"def get_edges\\\" -A 20\", \"path\": \"lenspr/database.py\"}...)\n",
      "\n",
      "--- Iteration 15 ---\n",
      "Tokens: +12035 in, +96 out\n",
      "Claude: Let me read the database.py file further to find the get_edges function:\n",
      "Tool: search_files({\"pattern\": \"get_edges\", \"path\": \"lenspr/database.py\"}...)\n",
      "\n",
      "❌ Max iterations reached\n",
      "\n",
      "Saved: results/task3_safe_change_without_lenspr.json\n"
     ]
    }
   ],
   "source": [
    "# Run WITHOUT LensPR\n",
    "result_without = run_benchmark(\"task3_safe_change\", with_lenspr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: Safe code change (with_lenspr)\n",
      "============================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Tokens: +4466 in, +128 out\n",
      "Claude: I'll analyze the impact of adding the `include_external: bool = False` parameter to the `get_connections` function in `lenspr/database.py`. Let me start by examining the function and its usage.\n",
      "Tool: lens_context({\"node_id\": \"lenspr.database.get_connections\", \"depth\": 2}...)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Tokens: +4678 in, +89 out\n",
      "Claude: Let me search for the function first to find the correct node ID:\n",
      "Tool: lens_search({\"query\": \"get_connections\", \"search_in\": \"name\"}...)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Tokens: +5085 in, +98 out\n",
      "Claude: Let me look at the actual implementation in `lenspr/database.py`:\n",
      "Tool: lens_list_nodes({\"file_path\": \"lenspr/database.py\", \"type\": \"function\"}...)\n",
      "\n",
      "--- Iteration 4 ---\n",
      "Tokens: +6578 in, +131 out\n",
      "Claude: I don't see a `get_connections` function in `lenspr/database.py`. Let me check what function might be related - I see `get_edges` which seems like it might be the function you're referring to:\n",
      "Tool: lens_context({\"node_id\": \"lenspr.database.get_edges\", \"depth\": 2}...)\n",
      "\n",
      "--- Iteration 5 ---\n",
      "Tokens: +8402 in, +137 out\n",
      "Claude: Now I can see that there's a `get_connections` function in `lenspr/__init__.py` that wraps the `get_edges` function in `lenspr/database.py`. Let me check for the impact on both functions:\n",
      "Tool: lens_check_impact({\"node_id\": \"lenspr.database.get_edges\", \"depth\": 3}...)\n",
      "\n",
      "--- Iteration 6 ---\n",
      "Tokens: +8945 in, +80 out\n",
      "Tool: lens_check_impact({\"node_id\": \"lenspr.get_connections\", \"depth\": 3}...)\n",
      "\n",
      "--- Iteration 7 ---\n",
      "Tokens: +9196 in, +84 out\n",
      "Claude: Let me get more detailed information about all the callers of `get_edges`:\n",
      "Tool: lens_find_usages({\"node_id\": \"lenspr.database.get_edges\"}...)\n",
      "\n",
      "--- Iteration 8 ---\n",
      "Tokens: +10344 in, +87 out\n",
      "Claude: Let me also check the MCP server function that wraps this:\n",
      "Tool: lens_context({\"node_id\": \"lenspr.mcp_server.run_server.lens_get_connections\"}...)\n",
      "\n",
      "--- Iteration 9 ---\n",
      "Tokens: +12027 in, +81 out\n",
      "Claude: Let me also check what the navigation handler looks like:\n",
      "Tool: lens_get_node({\"node_id\": \"lenspr.tools.navigation.handle_get_connections\"}...)\n",
      "\n",
      "--- Iteration 10 ---\n",
      "Tokens: +12550 in, +73 out\n",
      "Claude: Now let me examine some test files to understand the expected behavior:\n",
      "Tool: read_file({\"path\": \"tests/test_database.py\"}...)\n",
      "\n",
      "--- Iteration 11 ---\n",
      "Tokens: +14221 in, +772 out\n",
      "Claude: Now I have a comprehensive understanding of the system. Let me provide the impact analysis:\n",
      "Tool: task_complete({\"summary\": \"## Impact Analysis: Adding `include_external: bool = False` parameter to `get_connectio...)\n",
      "\n",
      "✅ Task completed: ## Impact Analysis: Adding `include_external: bool = False` parameter to `get_connections`\n",
      "\n",
      "Based on my analysis, I need to clarify that there is no `get_connections` function directly in `lenspr/database.py`. However, there are related functions that form a chain:\n",
      "\n",
      "1. **`lenspr.database.get_edges`** - The core database function\n",
      "2. **`lenspr.get_connections`** - A wrapper in `__init__.py` that calls `get_edges`\n",
      "3. **MCP server and tool handlers** - That expose this functionality\n",
      "\n",
      "### Affected Components (HIGH IMPACT - 16 nodes affected):\n",
      "\n",
      "**Direct Callers of `get_edges` (8 functions):**\n",
      "- `lenspr.get_connections` (wrapper function)\n",
      "- `lenspr.tools.navigation.handle_get_connections` (tool handler)\n",
      "- `lenspr.tools.modification.handle_rename` (uses for dependency analysis)\n",
      "- `lenspr.mcp_server.lens_get_connections` (MCP tool)\n",
      "- **5 test functions** in `test_database.py` and `test_mcp_server.py`\n",
      "\n",
      "**Chain of Dependencies:**\n",
      "- MCP server → tool handlers → `get_connections` → `get_edges`\n",
      "- CLI tools and rename functionality also depend on `get_edges`\n",
      "\n",
      "### Severity Assessment: **HIGH RISK**\n",
      "\n",
      "**Reasons:**\n",
      "1. **Breaking Change**: Adding a required parameter would break 8+ direct callers\n",
      "2. **Public API**: The function is exposed through MCP server and public API\n",
      "3. **Test Coverage**: 6 tests would need updates\n",
      "4. **Cross-module Impact**: Changes ripple through tools, MCP server, and core API\n",
      "\n",
      "### Required Updates if Changed:\n",
      "\n",
      "**Core Functions (2):**\n",
      "- `lenspr.database.get_edges` - Add the new parameter\n",
      "- `lenspr.get_connections` - Pass through the parameter\n",
      "\n",
      "**Tool Handlers (2):**\n",
      "- `lenspr.tools.navigation.handle_get_connections` - Handle new parameter\n",
      "- `lenspr.mcp_server.lens_get_connections` - Add parameter to MCP tool\n",
      "\n",
      "**Other Callers (1):**\n",
      "- `lenspr.tools.modification.handle_rename` - May need to specify the parameter\n",
      "\n",
      "**Tests (6):**\n",
      "- All test methods in `TestGetEdges` class\n",
      "- Integration test in MCP server tests\n",
      "\n",
      "### Recommendation:\n",
      "\n",
      "**Safe Approach**: Add the parameter with a default value (`False`) to maintain backward compatibility:\n",
      "```python\n",
      "def get_edges(node_id: str, db_path: Path, direction: str = \"both\", include_external: bool = False) -> list[Edge]:\n",
      "```\n",
      "\n",
      "This would:\n",
      "- ✅ Maintain backward compatibility\n",
      "- ✅ Allow gradual adoption\n",
      "- ✅ Not break existing tests\n",
      "- ✅ Not require immediate updates to all callers\n",
      "\n",
      "**Risk Level**: MEDIUM (with default parameter) vs HIGH (without default)\n",
      "\n",
      "Saved: results/task3_safe_change_with_lenspr.json\n"
     ]
    }
   ],
   "source": [
    "# Run WITH LensPR\n",
    "result_with = run_benchmark(\"task3_safe_change\", with_lenspr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results() -> dict:\n",
    "    \"\"\"Load all benchmark results.\"\"\"\n",
    "    results = {}\n",
    "    for path in RESULTS_DIR.glob(\"*.json\"):\n",
    "        result = BenchmarkResult.load(path)\n",
    "        key = f\"{result.task_id}_{result.mode}\"\n",
    "        results[key] = result\n",
    "    return results\n",
    "\n",
    "def compare_results(task_id: str, results: dict):\n",
    "    \"\"\"Compare with vs without LensPR for a task.\"\"\"\n",
    "    with_key = f\"{task_id}_with_lenspr\"\n",
    "    without_key = f\"{task_id}_without_lenspr\"\n",
    "    \n",
    "    if with_key not in results or without_key not in results:\n",
    "        print(f\"Missing results for {task_id}\")\n",
    "        return\n",
    "    \n",
    "    w = results[with_key]\n",
    "    wo = results[without_key]\n",
    "    \n",
    "    task_name = TASKS[task_id][\"name\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Task: {task_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\")\n",
    "    print(f\"{'Metric':<25} {'Without LensPR':>15} {'With LensPR':>15} {'Diff':>10}\")\n",
    "    print(f\"{'-'*65}\")\n",
    "    \n",
    "    # Input tokens\n",
    "    diff = wo.total_input_tokens - w.total_input_tokens\n",
    "    pct = (diff / wo.total_input_tokens * 100) if wo.total_input_tokens else 0\n",
    "    print(f\"{'Input tokens':<25} {wo.total_input_tokens:>15,} {w.total_input_tokens:>15,} {pct:>+9.1f}%\")\n",
    "    \n",
    "    # Output tokens\n",
    "    diff = wo.total_output_tokens - w.total_output_tokens\n",
    "    pct = (diff / wo.total_output_tokens * 100) if wo.total_output_tokens else 0\n",
    "    print(f\"{'Output tokens':<25} {wo.total_output_tokens:>15,} {w.total_output_tokens:>15,} {pct:>+9.1f}%\")\n",
    "    \n",
    "    # Iterations\n",
    "    print(f\"{'Iterations':<25} {wo.iterations:>15} {w.iterations:>15} {w.iterations - wo.iterations:>+10}\")\n",
    "    \n",
    "    # Tool calls\n",
    "    print(f\"{'Tool calls':<25} {wo.tool_call_count:>15} {w.tool_call_count:>15} {w.tool_call_count - wo.tool_call_count:>+10}\")\n",
    "    \n",
    "    # Completed\n",
    "    print(f\"{'Completed':<25} {str(wo.completed):>15} {str(w.completed):>15}\")\n",
    "    \n",
    "    # Tool breakdown\n",
    "    print(f\"\\nTool usage:\")\n",
    "    print(f\"  Without: {', '.join(t['name'] for t in wo.tool_calls[:10])}\")\n",
    "    print(f\"  With:    {', '.join(t['name'] for t in w.tool_calls[:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 results\n",
      "\n",
      "============================================================\n",
      "Task: Understand a function\n",
      "============================================================\n",
      "\n",
      "Metric                     Without LensPR     With LensPR       Diff\n",
      "-----------------------------------------------------------------\n",
      "Input tokens                       89,800         117,649     -31.0%\n",
      "Output tokens                       1,200           2,199     -83.2%\n",
      "Iterations                             15              13         -2\n",
      "Tool calls                             15              13         -2\n",
      "Completed                           False            True\n",
      "\n",
      "Tool usage:\n",
      "  Without: read_file, search_files, read_file, search_files, search_files, search_files, search_files, search_files, search_files, list_files\n",
      "  With:    lens_context, lens_search, lens_list_nodes, lens_list_nodes, lens_context, lens_find_usages, lens_context, lens_context, lens_search, lens_get_node\n",
      "\n",
      "============================================================\n",
      "Task: Find all usages\n",
      "============================================================\n",
      "\n",
      "Metric                     Without LensPR     With LensPR       Diff\n",
      "-----------------------------------------------------------------\n",
      "Input tokens                      113,004         108,364      +4.1%\n",
      "Output tokens                       1,286           1,760     -36.9%\n",
      "Iterations                             15              10         -5\n",
      "Tool calls                             15              10         -5\n",
      "Completed                           False            True\n",
      "\n",
      "Tool usage:\n",
      "  Without: list_files, list_files, read_file, search_files, read_file, search_files, search_files, search_files, search_files, search_files\n",
      "  With:    lens_context, lens_find_usages, lens_grep, lens_grep, lens_grep, lens_grep, lens_grep, lens_grep, lens_grep, task_complete\n",
      "\n",
      "============================================================\n",
      "Task: Safe code change\n",
      "============================================================\n",
      "\n",
      "Metric                     Without LensPR     With LensPR       Diff\n",
      "-----------------------------------------------------------------\n",
      "Input tokens                      112,030          96,492     +13.9%\n",
      "Output tokens                       1,410           1,760     -24.8%\n",
      "Iterations                             15              11         -4\n",
      "Tool calls                             15              11         -4\n",
      "Completed                           False            True\n",
      "\n",
      "Tool usage:\n",
      "  Without: list_files, list_files, read_file, search_files, read_file, search_files, search_files, search_files, read_file, search_files\n",
      "  With:    lens_context, lens_search, lens_list_nodes, lens_context, lens_check_impact, lens_check_impact, lens_find_usages, lens_context, lens_get_node, read_file\n"
     ]
    }
   ],
   "source": [
    "# Load and compare all results\n",
    "results = load_all_results()\n",
    "print(f\"Loaded {len(results)} results\")\n",
    "\n",
    "for task_id in TASKS.keys():\n",
    "    compare_results(task_id, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY: LensPR Impact on Claude Code Performance\n",
      "================================================================================\n",
      "\n",
      "Task                           Mode                 Input     Output   Iter  Tools\n",
      "--------------------------------------------------------------------------------\n",
      "Understand a function          WITHOUT             89,800      1,200     15     15\n",
      "Understand a function          WITH               117,649      2,199     13     13\n",
      "\n",
      "Find all usages                WITHOUT            113,004      1,286     15     15\n",
      "Find all usages                WITH               108,364      1,760     10     10\n",
      "\n",
      "Safe code change               WITHOUT            112,030      1,410     15     15\n",
      "Safe code change               WITH                96,492      1,760     11     11\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TOTAL                          WITHOUT            314,834      3,896     45     45\n",
      "TOTAL                          WITH               322,505      5,719     34     34\n",
      "\n",
      "📊 Input token savings: -2.4%\n",
      "📊 Iteration savings: 24.4%\n"
     ]
    }
   ],
   "source": [
    "def summary_table(results: dict):\n",
    "    \"\"\"Generate summary comparison table.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY: LensPR Impact on Claude Code Performance\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    totals = {\"with\": {\"in\": 0, \"out\": 0, \"iter\": 0, \"tools\": 0},\n",
    "              \"without\": {\"in\": 0, \"out\": 0, \"iter\": 0, \"tools\": 0}}\n",
    "    \n",
    "    print(f\"{'Task':<30} {'Mode':<15} {'Input':>10} {'Output':>10} {'Iter':>6} {'Tools':>6}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for task_id in TASKS.keys():\n",
    "        for mode in [\"without_lenspr\", \"with_lenspr\"]:\n",
    "            key = f\"{task_id}_{mode}\"\n",
    "            if key in results:\n",
    "                r = results[key]\n",
    "                mode_short = \"WITHOUT\" if \"without\" in mode else \"WITH\"\n",
    "                print(f\"{TASKS[task_id]['name']:<30} {mode_short:<15} {r.total_input_tokens:>10,} {r.total_output_tokens:>10,} {r.iterations:>6} {r.tool_call_count:>6}\")\n",
    "                \n",
    "                m = \"without\" if \"without\" in mode else \"with\"\n",
    "                totals[m][\"in\"] += r.total_input_tokens\n",
    "                totals[m][\"out\"] += r.total_output_tokens\n",
    "                totals[m][\"iter\"] += r.iterations\n",
    "                totals[m][\"tools\"] += r.tool_call_count\n",
    "        print()\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'TOTAL':<30} {'WITHOUT':<15} {totals['without']['in']:>10,} {totals['without']['out']:>10,} {totals['without']['iter']:>6} {totals['without']['tools']:>6}\")\n",
    "    print(f\"{'TOTAL':<30} {'WITH':<15} {totals['with']['in']:>10,} {totals['with']['out']:>10,} {totals['with']['iter']:>6} {totals['with']['tools']:>6}\")\n",
    "    \n",
    "    # Calculate savings\n",
    "    if totals['without']['in'] > 0:\n",
    "        in_savings = (totals['without']['in'] - totals['with']['in']) / totals['without']['in'] * 100\n",
    "        print(f\"\\n📊 Input token savings: {in_savings:.1f}%\")\n",
    "    if totals['without']['iter'] > 0:\n",
    "        iter_savings = (totals['without']['iter'] - totals['with']['iter']) / totals['without']['iter'] * 100\n",
    "        print(f\"📊 Iteration savings: {iter_savings:.1f}%\")\n",
    "\n",
    "summary_table(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
